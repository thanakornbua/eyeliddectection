<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/README.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/README.md" />
              <option name="originalContent" value="# Eyelid Detection&#10;&#10;CPU-only eyelid state monitor using OpenCV + MediaPipe. Provides live state (open/closed), eyelid distance via eye-aspect ratio (EAR), and blink rate per minute.&#10;&#10;## Setup&#10;&#10;```bash&#10;python -m venv .venv&#10;source .venv/bin/activate&#10;pip install -r requirements.txt&#10;```&#10;&#10;## Usage&#10;&#10;```bash&#10;python -m src.main --camera 0 --threshold 0.21 --window 60 --fps 30&#10;```&#10;&#10;Press `q` to exit the preview window. Add `--headless` to disable the window and stream logs to stdout.&#10;&#10;## Notes&#10;&#10;- EAR threshold `0.21` works for many setups; adjust per user by lowering when false positives occur or raising if blinks are missed.&#10;- Blink rate window determines how many seconds of history contribute to blinks/min computation. `60` seconds mimics a rolling minute average.&#10;- Mediapipe face mesh runs fully on CPU by default; ensure adequate lighting for stable landmarks.&#10;&#10;" />
              <option name="updatedContent" value="# Eyelid Detection&#10;&#10;CPU-only eyelid state monitor using OpenCV + MediaPipe. Provides live state (open/closed), eyelid distance via eye-aspect ratio (EAR), and blink rate per minute.&#10;&#10;## Setup&#10;&#10;```bash&#10;python -m venv .venv&#10;source .venv/bin/activate&#10;pip install -r requirements.txt&#10;```&#10;&#10;## Usage&#10;&#10;```bash&#10;python -m src.main --camera 0 --threshold 0.21 --window 60 --fps 30 --pitch-threshold 10 --landmarks&#10;```&#10;&#10;Press `q` to exit the preview window. Use `--headless` to log stats in the console and `--landmarks` to draw landmarks.&#10;&#10;## Notes&#10;&#10;- EAR threshold `0.21` works for many setups; adjust per user by lowering when false positives occur or raising if blinks are missed.&#10;- Blink rate window determines how many seconds of history contribute to blinks/min computation. `60` seconds mimics a rolling minute average.&#10;- Mediapipe face mesh runs fully on CPU by default; ensure adequate lighting for stable landmarks.&#10;- Use `--pitch-threshold` (degrees) and `--pitch-alpha` for nod detection sensitivity. HUD size and margins are customizable via `--hud-*` flags." />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/requirements.txt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/requirements.txt" />
              <option name="originalContent" value="opencv-python&gt;=4.9&#10;mediapipe&gt;=0.10&#10;numpy&gt;=1.26&#10;&#10;" />
              <option name="updatedContent" value="opencv-python&gt;=4.9&#10;mediapipe&gt;=0.10&#10;numpy&gt;=1.26" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/__init__.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/__init__.py" />
              <option name="updatedContent" value="&quot;&quot;&quot;Eyelid detection package&quot;&quot;&quot;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/eyelid_metrics.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/eyelid_metrics.py" />
              <option name="originalContent" value="import math&#10;from dataclasses import dataclass&#10;from typing import Iterable, List, Optional, Tuple&#10;&#10;import cv2&#10;import mediapipe as mp&#10;import numpy as np&#10;&#10;&#10;@dataclass&#10;class EyeMeasurement:&#10;    eyelid_distance: float&#10;    eye_aspect_ratio: float&#10;    is_closed: bool&#10;&#10;&#10;class MediapipeEyelidDetector:&#10;    def __init__(&#10;        self,&#10;        detection_confidence: float = 0.6,&#10;        tracking_confidence: float = 0.6,&#10;        eyelid_threshold: float = 0.21,&#10;    ) -&gt; None:&#10;        self.eyelid_threshold = eyelid_threshold&#10;        self.face_mesh = mp.solutions.face_mesh.FaceMesh(&#10;            max_num_faces=1,&#10;            refine_landmarks=True,&#10;            min_detection_confidence=detection_confidence,&#10;            min_tracking_confidence=tracking_confidence,&#10;        )&#10;&#10;    def close(self) -&gt; None:&#10;        self.face_mesh.close()&#10;&#10;    def process_frame(self, frame: np.ndarray) -&gt; Optional[EyeMeasurement]:&#10;        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)&#10;        results = self.face_mesh.process(rgb)&#10;        if not results.multi_face_landmarks:&#10;            return None&#10;&#10;        landmarks = results.multi_face_landmarks[0]&#10;        eye_indices = {&#10;            &quot;left&quot;: [33, 160, 158, 133, 153, 144],&#10;            &quot;right&quot;: [263, 387, 385, 362, 380, 373],&#10;        }&#10;&#10;        def calc_ratio(indices: Iterable[int]) -&gt; Tuple[float, float]:&#10;            pts = np.array(&#10;                [(landmarks.landmark[i].x, landmarks.landmark[i].y) for i in indices],&#10;                dtype=np.float32,&#10;            )&#10;            vertical = np.linalg.norm(pts[1] - pts[5]) + np.linalg.norm(pts[2] - pts[4])&#10;            horizontal = np.linalg.norm(pts[0] - pts[3])&#10;            ratio = vertical / (2.0 * horizontal + 1e-6)&#10;            return vertical, ratio&#10;&#10;        lid_distances, ratios = [], []&#10;        for eye in eye_indices.values():&#10;            vertical, ratio = calc_ratio(eye)&#10;            lid_distances.append(vertical)&#10;            ratios.append(ratio)&#10;&#10;        eyelid_distance = float(np.mean(lid_distances))&#10;        ear = float(np.mean(ratios))&#10;        is_closed = ear &lt; self.eyelid_threshold&#10;        return EyeMeasurement(eyelid_distance=eyelid_distance, eye_aspect_ratio=ear, is_closed=is_closed)&#10;&#10;&#10;&#10;" />
              <option name="updatedContent" value="import math&#10;from dataclasses import dataclass&#10;from typing import Iterable, List, Optional, Tuple&#10;&#10;import cv2&#10;import mediapipe as mp&#10;import numpy as np&#10;&#10;&#10;@dataclass&#10;class EyeMeasurement:&#10;    eyelid_distance: float&#10;    eye_aspect_ratio: float&#10;    is_closed: bool&#10;&#10;&#10;def _angle_between(v1: np.ndarray, v2: np.ndarray) -&gt; float:&#10;    v1_u = v1 / (np.linalg.norm(v1) + 1e-6)&#10;    v2_u = v2 / (np.linalg.norm(v2) + 1e-6)&#10;    dot = np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)&#10;    return float(np.degrees(np.arccos(dot)))&#10;&#10;&#10;@dataclass&#10;class FaceMeasurement:&#10;    eye: EyeMeasurement&#10;    pitch_deg: float&#10;    landmarks_px: Optional[np.ndarray]&#10;&#10;&#10;class MediapipeEyelidDetector:&#10;    def __init__(&#10;        self,&#10;        detection_confidence: float = 0.6,&#10;        tracking_confidence: float = 0.6,&#10;        eyelid_threshold: float = 0.21,&#10;        pitch_alpha: float = 0.2,&#10;    ) -&gt; None:&#10;        self.eyelid_threshold = eyelid_threshold&#10;        self.pitch_alpha = pitch_alpha&#10;        self._pitch_estimate: Optional[float] = None&#10;        self.face_mesh = mp.solutions.face_mesh.FaceMesh(&#10;            max_num_faces=1,&#10;            refine_landmarks=True,&#10;            min_detection_confidence=detection_confidence,&#10;            min_tracking_confidence=tracking_confidence,&#10;        )&#10;&#10;    def close(self) -&gt; None:&#10;        self.face_mesh.close()&#10;&#10;    def process_frame(self, frame: np.ndarray, include_landmarks: bool = False) -&gt; Optional[FaceMeasurement]:&#10;        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)&#10;        results = self.face_mesh.process(rgb)&#10;        if not results.multi_face_landmarks:&#10;            return None&#10;&#10;        landmarks = results.multi_face_landmarks[0]&#10;        coords = np.array(&#10;            [(lm.x, lm.y, lm.z) for lm in landmarks.landmark],&#10;            dtype=np.float32,&#10;        )&#10;        eye_indices = {&#10;            &quot;left&quot;: [33, 160, 158, 133, 153, 144],&#10;            &quot;right&quot;: [263, 387, 385, 362, 380, 373],&#10;        }&#10;&#10;        def calc_ratio(indices: Iterable[int]) -&gt; Tuple[float, float]:&#10;            pts = coords[indices][:, :2]&#10;            vertical = np.linalg.norm(pts[1] - pts[5]) + np.linalg.norm(pts[2] - pts[4])&#10;            horizontal = np.linalg.norm(pts[0] - pts[3])&#10;            ratio = vertical / (2.0 * horizontal + 1e-6)&#10;            return vertical, ratio&#10;&#10;        lid_distances, ratios = [], []&#10;        for eye in eye_indices.values():&#10;            vertical, ratio = calc_ratio(eye)&#10;            lid_distances.append(vertical)&#10;            ratios.append(ratio)&#10;&#10;        eyelid_distance = float(np.mean(lid_distances))&#10;        ear = float(np.mean(ratios))&#10;        is_closed = ear &lt; self.eyelid_threshold&#10;        eye_measurement = EyeMeasurement(&#10;            eyelid_distance=eyelid_distance,&#10;            eye_aspect_ratio=ear,&#10;            is_closed=is_closed,&#10;        )&#10;&#10;        forehead = coords[10]&#10;        chin = coords[152]&#10;        pitch_value = _angle_between(chin - coords[1], np.array([0.0, 1.0, 0.0]))&#10;&#10;        landmarks_px = None&#10;        if include_landmarks:&#10;            h, w = frame.shape[:2]&#10;            landmarks_px = np.column_stack((coords[:, 0] * w, coords[:, 1] * h))&#10;&#10;        if self._pitch_estimate is None:&#10;            self._pitch_estimate = pitch_value&#10;        else:&#10;            self._pitch_estimate = (&#10;                self.pitch_alpha * pitch_value + (1.0 - self.pitch_alpha) * self._pitch_estimate&#10;            )&#10;&#10;        return FaceMeasurement(&#10;            eye=eye_measurement,&#10;            pitch_deg=float(self._pitch_estimate),&#10;            landmarks_px=landmarks_px,&#10;        )" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/main.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/main.py" />
              <option name="originalContent" value="import argparse&#10;import time&#10;import cv2&#10;&#10;from .blink_tracker import BlinkTracker&#10;from .eyelid_metrics import MediapipeEyelidDetector&#10;&#10;&#10;def parse_args() -&gt; argparse.Namespace:&#10;    parser = argparse.ArgumentParser(description=&quot;Eyelid distance and blink rate monitor&quot;)&#10;    parser.add_argument(&quot;--camera&quot;, type=int, default=0, help=&quot;Camera index&quot;)&#10;    parser.add_argument(&quot;--threshold&quot;, type=float, default=0.21, help=&quot;EAR threshold for closed eye&quot;)&#10;    parser.add_argument(&quot;--window&quot;, type=float, default=60.0, help=&quot;Blink rate window in seconds&quot;)&#10;    parser.add_argument(&quot;--fps&quot;, type=float, default=30.0, help=&quot;Assumed camera fps for debounce&quot;)&#10;    parser.add_argument(&quot;--headless&quot;, action=&quot;store_true&quot;, help=&quot;Disable video preview, log to stdout&quot;)&#10;    parser.add_argument(&quot;--noshow&quot;, action=&quot;store_true&quot;, help=&quot;Alias for --headless&quot;)&#10;    parser.add_argument(&quot;--pitch-threshold&quot;, type=float, default=0.025, help=&quot;Pitch delta to classify nodding&quot;)&#10;    parser.add_argument(&quot;--landmarks&quot;, action=&quot;store_true&quot;, help=&quot;Overlay landmarks for debugging&quot;)&#10;    return parser.parse_args()&#10;&#10;&#10;def main() -&gt; None:&#10;    args = parse_args()&#10;    detector = MediapipeEyelidDetector(eyelid_threshold=args.threshold)&#10;    tracker = BlinkTracker(&#10;        blink_confirm_frames=max(1, int(args.fps * 0.1)),&#10;        window_seconds=args.window,&#10;    )&#10;&#10;    cap = cv2.VideoCapture(args.camera)&#10;    if not cap.isOpened():&#10;        raise RuntimeError(&quot;Cannot open camera&quot;)&#10;&#10;    try:&#10;        while True:&#10;            ret, frame = cap.read()&#10;            if not ret:&#10;                break&#10;&#10;            measurement = detector.process_frame(frame, include_landmarks=args.landmarks)&#10;            if measurement is None:&#10;                continue&#10;&#10;            blink_state = tracker.update(measurement.eye.is_closed)&#10;            eyelid_state = &quot;closed&quot; if blink_state.is_closed else &quot;open&quot;&#10;            is_nodding = measurement.pitch_deg &gt; args.pitch_threshold&#10;            nod_state = &quot;nodding&quot; if is_nodding else &quot;steady&quot;&#10;            caption = (&#10;                f&quot;state: {eyelid_state}/{nod_state} | EAR: {measurement.eye.eye_aspect_ratio:.3f} | &quot;&#10;                f&quot;blink/min: {blink_state.blink_rate_per_min:.1f} | total: {blink_state.total_blinks}&quot;&#10;            )&#10;&#10;            if args.headless or args.noshow:&#10;                print(f&quot;{time.time():.3f} {caption}&quot;)&#10;            else:&#10;                overlay = frame.copy()&#10;                if args.landmarks and measurement.landmarks_px is not None:&#10;                    for x, y in measurement.landmarks_px.astype(int):&#10;                        cv2.circle(overlay, (x, y), 1, (255, 0, 0), -1)&#10;                    frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)&#10;&#10;                cv2.putText(frame, caption, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)&#10;                cv2.imshow(&quot;Eyelid Monitor&quot;, frame)&#10;                if cv2.waitKey(1) &amp; 0xFF == ord(&quot;q&quot;):&#10;                    break&#10;    finally:&#10;        detector.close()&#10;        cap.release()&#10;        cv2.destroyAllWindows()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="import argparse&#10;import time&#10;import cv2&#10;&#10;from .blink_tracker import BlinkTracker&#10;from .eyelid_metrics import MediapipeEyelidDetector&#10;&#10;&#10;def parse_args() -&gt; argparse.Namespace:&#10;    parser = argparse.ArgumentParser(description=&quot;Eyelid distance and blink rate monitor&quot;)&#10;    parser.add_argument(&quot;--camera&quot;, type=int, default=0, help=&quot;Camera index&quot;)&#10;    parser.add_argument(&quot;--threshold&quot;, type=float, default=0.21, help=&quot;EAR threshold for closed eye&quot;)&#10;    parser.add_argument(&quot;--window&quot;, type=float, default=60.0, help=&quot;Blink rate window in seconds&quot;)&#10;    parser.add_argument(&quot;--fps&quot;, type=float, default=30.0, help=&quot;Assumed camera fps for debounce&quot;)&#10;    parser.add_argument(&quot;--headless&quot;, action=&quot;store_true&quot;, help=&quot;Disable video preview, log to stdout&quot;)&#10;    parser.add_argument(&quot;--noshow&quot;, action=&quot;store_true&quot;, help=&quot;Alias for --headless&quot;)&#10;    parser.add_argument(&quot;--pitch-threshold&quot;, type=float, default=10.0, help=&quot;Pitch degrees to classify nodding&quot;)&#10;    parser.add_argument(&quot;--landmarks&quot;, action=&quot;store_true&quot;, help=&quot;Overlay landmarks for debugging&quot;)&#10;    parser.add_argument(&quot;--hud-width&quot;, type=int, default=380, help=&quot;HUD box width in pixels&quot;)&#10;    parser.add_argument(&quot;--hud-height&quot;, type=int, default=120, help=&quot;HUD box height in pixels&quot;)&#10;    parser.add_argument(&quot;--hud-margin&quot;, type=int, default=10, help=&quot;Margin from top-left corner for HUD&quot;)&#10;    parser.add_argument(&quot;--pitch-alpha&quot;, type=float, default=0.2, help=&quot;Smoothing for pitch degrees&quot;)&#10;    return parser.parse_args()&#10;&#10;&#10;hud_bg_color = (20, 20, 20)&#10;hud_border_color = (0, 255, 0)&#10;hud_text_color = (220, 220, 220)&#10;&#10;def _draw_hud(frame, caption_lines, hud_rect):&#10;    x, y, w, h = hud_rect&#10;    overlay = frame.copy()&#10;    cv2.rectangle(overlay, (x, y), (x + w, y + h), hud_bg_color, -1)&#10;    frame[:] = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)&#10;    cv2.rectangle(frame, (x, y), (x + w, y + h), hud_border_color, 2)&#10;    line_y = y + 25&#10;    for line in caption_lines:&#10;        cv2.putText(frame, line, (x + 15, line_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, hud_text_color, 2)&#10;        line_y += 28&#10;&#10;&#10;def main() -&gt; None:&#10;    args = parse_args()&#10;    detector = MediapipeEyelidDetector(&#10;        eyelid_threshold=args.threshold,&#10;        pitch_alpha=args.pitch_alpha,&#10;    )&#10;    tracker = BlinkTracker(&#10;        blink_confirm_frames=max(1, int(args.fps * 0.1)),&#10;        window_seconds=args.window,&#10;    )&#10;&#10;    cap = cv2.VideoCapture(args.camera)&#10;    if not cap.isOpened():&#10;        raise RuntimeError(&quot;Cannot open camera&quot;)&#10;&#10;    try:&#10;        while True:&#10;            ret, frame = cap.read()&#10;            if not ret:&#10;                break&#10;&#10;            measurement = detector.process_frame(frame, include_landmarks=args.landmarks)&#10;            if measurement is None:&#10;                continue&#10;&#10;            blink_state = tracker.update(measurement.eye.is_closed)&#10;            eyelid_state = &quot;closed&quot; if blink_state.is_closed else &quot;open&quot;&#10;            is_nodding = measurement.pitch_deg &gt; args.pitch_threshold&#10;            nod_state = &quot;nodding&quot; if is_nodding else &quot;steady&quot;&#10;&#10;            caption_lines = [&#10;                f&quot;eyes: {eyelid_state} | EAR {measurement.eye.eye_aspect_ratio:.3f}&quot;,&#10;                f&quot;nod: {nod_state} ({measurement.pitch_deg:.1f}Â°)&quot;,&#10;                f&quot;blink/min: {blink_state.blink_rate_per_min:.1f}&quot;,&#10;                f&quot;total blinks: {blink_state.total_blinks}&quot;,&#10;            ]&#10;&#10;            if args.headless or args.noshow:&#10;                print(f&quot;{time.time():.3f} &quot; + &quot; | &quot;.join(caption_lines))&#10;            else:&#10;                if args.landmarks and measurement.landmarks_px is not None:&#10;                    for x_lm, y_lm in measurement.landmarks_px.astype(int):&#10;                        cv2.circle(frame, (x_lm, y_lm), 1, (255, 0, 0), -1)&#10;&#10;                hud_rect = (&#10;                    args.hud_margin,&#10;                    args.hud_margin,&#10;                    args.hud_width,&#10;                    args.hud_height,&#10;                )&#10;                _draw_hud(frame, caption_lines, hud_rect)&#10;&#10;                cv2.imshow(&quot;Eyelid Monitor&quot;, frame)&#10;                if cv2.waitKey(1) &amp; 0xFF == ord(&quot;q&quot;):&#10;                    break&#10;    finally:&#10;        detector.close()&#10;        cap.release()&#10;        cv2.destroyAllWindows()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>